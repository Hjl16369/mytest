# ------------------------------------------------------------
# æ–‡ä»¶åï¼šsafety_stock_app.py
# åŠŸèƒ½ï¼šåŸºäºèˆ¹æœŸã€é”€å”®ä¸è¿è¾“å‘¨æœŸæ³¢åŠ¨çš„åŠ¨æ€å®‰å…¨åº“å­˜è®¡ç®—ç³»ç»Ÿ
# è¿è¡Œæ–¹å¼ï¼šstreamlit run safety_stock_app.py
# ------------------------------------------------------------

import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from scipy.stats import norm
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(
    page_title="åŠ¨æ€å®‰å…¨åº“å­˜ä¼˜åŒ–ç³»ç»Ÿ", 
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“¦ ä¾›åº”é“¾å®‰å…¨åº“å­˜åŠ¨æ€ä¼˜åŒ–ç³»ç»Ÿ")
st.markdown("""
è¯¥ç³»ç»Ÿç”¨äºåœ¨**èˆ¹æœŸä¸å›ºå®š**ã€**è¿è¾“å‘¨æœŸä¸ç¡®å®š**çš„æ¡ä»¶ä¸‹ï¼Œ
è‡ªåŠ¨è®¡ç®—æœ€ä¼˜çš„å®‰å…¨åº“å­˜ï¼ˆSafety Stockï¼‰å’Œå†è®¢è´§ç‚¹ï¼ˆReorder Pointï¼‰ï¼Œ
ä»¥å®ç°**ä¸æ–­è´§ä¸”åº“å­˜æœ€å°åŒ–**ã€‚
""")

# ---------------------------
# ä¾§è¾¹æ é…ç½®
# ---------------------------
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    service = st.slider(
        "ç›®æ ‡æœåŠ¡æ°´å¹³ï¼ˆService Levelï¼‰", 
        0.80, 0.999, 0.95, 0.01,
        help="æœåŠ¡æ°´å¹³è¶Šé«˜ï¼Œå®‰å…¨åº“å­˜è¶Šå¤§ï¼Œæ–­è´§é£é™©è¶Šä½"
    )
    st.write(f"**å½“å‰æœåŠ¡æ°´å¹³ï¼š{service:.2%}**")
    
    st.divider()
    
    show_advanced = st.checkbox("æ˜¾ç¤ºé«˜çº§é€‰é¡¹", value=False)
    if show_advanced:
        use_custom_leadtime = st.checkbox("ä½¿ç”¨è‡ªå®šä¹‰è¿è¾“å‘¨æœŸ", value=False)
        if use_custom_leadtime:
            custom_mu_l = st.number_input("å¹³å‡è¿è¾“å‘¨æœŸï¼ˆå¤©ï¼‰", 0.0, 365.0, 30.0, 1.0)
            custom_sigma_l = st.number_input("è¿è¾“å‘¨æœŸæ ‡å‡†å·®ï¼ˆå¤©ï¼‰", 0.0, 100.0, 5.0, 0.5)
    else:
        use_custom_leadtime = False
        custom_mu_l = None
        custom_sigma_l = None
    
    st.divider()
    st.caption("Â© 2025 sisleyä¾›åº”é“¾æ™ºèƒ½åˆ†æå®éªŒå®¤")

# ---------------------------
# æ•°æ®è¯»å–å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ---------------------------
@st.cache_data(show_spinner=False)
def read_data(uploaded_file):
    """è¯»å–å¹¶æ ‡å‡†åŒ–ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶"""
    try:
        if uploaded_file is None:
            return None
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
        if uploaded_file.name.endswith(".xlsx"):
            df = pd.read_excel(uploaded_file, engine='openpyxl')
        elif uploaded_file.name.endswith(".xls"):
            df = pd.read_excel(uploaded_file, engine='xlrd')
        else:
            # å°è¯•ä¸åŒç¼–ç è¯»å–CSV
            try:
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            except:
                uploaded_file.seek(0)
                df = pd.read_csv(uploaded_file, encoding='gbk')
        
        # æ ‡å‡†åŒ–åˆ—å
        df.columns = [c.lower().strip().replace(' ', '_') for c in df.columns]
        
        return df
    
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

# ---------------------------
# æ•°æ®éªŒè¯å‡½æ•°
# ---------------------------
def validate_ship_schedule(df):
    """éªŒè¯èˆ¹æœŸè¡¨æ ¼å¼"""
    if df is None:
        return False, "æ•°æ®ä¸ºç©º"
    
    required_cols = ['date']
    missing = [col for col in required_cols if col not in df.columns]
    
    if missing:
        return False, f"ç¼ºå°‘å¿…éœ€åˆ—ï¼š{', '.join(missing)}"
    
    try:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        if df['date'].isna().all():
            return False, "dateåˆ—æ— æ³•è§£æä¸ºæ—¥æœŸæ ¼å¼"
    except:
        return False, "dateåˆ—æ ¼å¼é”™è¯¯"
    
    return True, f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡èˆ¹æœŸè®°å½•"

def validate_sales_history(df):
    """éªŒè¯é”€å”®è®°å½•æ ¼å¼"""
    if df is None:
        return False, "æ•°æ®ä¸ºç©º"
    
    required_cols = ['date', 'sku', 'quantity']
    missing = [col for col in required_cols if col not in df.columns]
    
    if missing:
        return False, f"ç¼ºå°‘å¿…éœ€åˆ—ï¼š{', '.join(missing)}"
    
    try:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')
        
        if df['date'].isna().all():
            return False, "dateåˆ—æ— æ³•è§£æä¸ºæ—¥æœŸæ ¼å¼"
        if df['quantity'].isna().all():
            return False, "quantityåˆ—æ— æ³•è§£æä¸ºæ•°å€¼æ ¼å¼"
        
        # ç»Ÿè®¡ä¿¡æ¯
        n_skus = df['sku'].nunique()
        date_range = f"{df['date'].min().date()} è‡³ {df['date'].max().date()}"
        
    except Exception as e:
        return False, f"æ•°æ®æ ¼å¼é”™è¯¯ï¼š{str(e)}"
    
    return True, f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡é”€å”®è®°å½•ï¼Œæ¶µç›– {n_skus} ä¸ªSKUï¼Œæ—¶é—´èŒƒå›´ï¼š{date_range}"

def validate_leadtime_history(df):
    """éªŒè¯è¿è¾“å‘¨æœŸè®°å½•æ ¼å¼"""
    if df is None:
        return True, "æœªä¸Šä¼ è¿è¾“å‘¨æœŸè®°å½•ï¼ˆå¯é€‰ï¼‰"
    
    has_leadtime_col = 'lead_time_days' in df.columns
    has_date_cols = 'order_date' in df.columns and 'arrival_date' in df.columns
    
    if not (has_leadtime_col or has_date_cols):
        return False, "éœ€è¦åŒ…å« 'lead_time_days' æˆ– ('order_date' + 'arrival_date') åˆ—"
    
    try:
        if has_leadtime_col:
            df['lead_time_days'] = pd.to_numeric(df['lead_time_days'], errors='coerce')
            if df['lead_time_days'].isna().all():
                return False, "lead_time_daysåˆ—æ— æ³•è§£æä¸ºæ•°å€¼"
        else:
            df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')
            df['arrival_date'] = pd.to_datetime(df['arrival_date'], errors='coerce')
            if df['order_date'].isna().all() or df['arrival_date'].isna().all():
                return False, "æ—¥æœŸåˆ—æ— æ³•è§£æ"
    except Exception as e:
        return False, f"æ•°æ®æ ¼å¼é”™è¯¯ï¼š{str(e)}"
    
    return True, f"âœ… æˆåŠŸè¯»å– {len(df)} æ¡è¿è¾“å‘¨æœŸè®°å½•"

# ---------------------------
# ä¸Šä¼ æ•°æ®åŒºåŸŸ
# ---------------------------
st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")

col1, col2, col3 = st.columns(3)

with col1:
    ship_file = st.file_uploader(
        "â‘  ä¸Šä¼ èˆ¹æœŸè¡¨ï¼ˆShip Scheduleï¼‰", 
        type=["csv", "xlsx", "xls"],
        help="å¿…éœ€ï¼šåŒ…å«èˆ¹æœŸå‡ºå‘æ—¥æœŸä¿¡æ¯"
    )
    if ship_file:
        ship_df = read_data(ship_file)
        valid, msg = validate_ship_schedule(ship_df)
        if valid:
            st.success(msg)
            ship_df['date'] = pd.to_datetime(ship_df['date'])
        else:
            st.error(msg)
            ship_df = None

with col2:
    sales_file = st.file_uploader(
        "â‘¡ ä¸Šä¼ é”€å”®è®°å½•ï¼ˆSales Historyï¼‰", 
        type=["csv", "xlsx", "xls"],
        help="å¿…éœ€ï¼šåŒ…å«æ—¥æœŸã€SKUã€é”€é‡ä¿¡æ¯"
    )
    if sales_file:
        sales_df = read_data(sales_file)
        valid, msg = validate_sales_history(sales_df)
        if valid:
            st.success(msg)
            sales_df['date'] = pd.to_datetime(sales_df['date'])
            sales_df['quantity'] = pd.to_numeric(sales_df['quantity'])
        else:
            st.error(msg)
            sales_df = None

with col3:
    leadtime_file = st.file_uploader(
        "â‘¢ ä¸Šä¼ è¿è¾“å‘¨æœŸè®°å½•ï¼ˆå¯é€‰ï¼‰", 
        type=["csv", "xlsx", "xls"],
        help="å¯é€‰ï¼šåŒ…å«è®¢å•æ—¥æœŸå’Œåˆ°è´§æ—¥æœŸæˆ–è¿è¾“å¤©æ•°"
    )
    if leadtime_file:
        lead_df = read_data(leadtime_file)
        valid, msg = validate_leadtime_history(lead_df)
        if valid:
            st.success(msg)
        else:
            st.error(msg)
            lead_df = None
    else:
        lead_df = None

# ---------------------------
# åˆ†æå‡½æ•°å®šä¹‰ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ---------------------------
def compute_demand_stats(sales_df, sku=None):
    """è®¡ç®—éœ€æ±‚ç»Ÿè®¡é‡"""
    df = sales_df.copy()
    
    # ç­›é€‰SKU
    if sku is not None:
        df = df[df["sku"] == sku]
    
    if len(df) == 0:
        return 0, 0, 0
    
    # åˆ›å»ºå®Œæ•´æ—¥æœŸèŒƒå›´å¹¶å¡«å……ç¼ºå¤±å€¼
    date_range = pd.date_range(df["date"].min(), df["date"].max(), freq="D")
    daily = df.groupby("date")["quantity"].sum().reindex(date_range, fill_value=0)
    
    mu_d = daily.mean()
    sigma_d = daily.std(ddof=1) if len(daily) > 1 else 0
    
    # è®¡ç®—éœ€æ±‚å˜å¼‚ç³»æ•°ï¼ˆCVï¼‰ä½œä¸ºéœ€æ±‚æ³¢åŠ¨çš„è¡¡é‡æŒ‡æ ‡
    cv = (sigma_d / mu_d * 100) if mu_d > 0 else 0
    
    return mu_d, sigma_d, cv

def derive_leadtime_from_schedule(schedule_df):
    """ä»èˆ¹æœŸæ¨ç®—è¿è¾“å‘¨æœŸ"""
    dates = schedule_df["date"].sort_values().reset_index(drop=True)
    intervals = dates.diff().dt.days.dropna()
    
    if len(intervals) == 0:
        return 30, 5  # é»˜è®¤å€¼
    
    # èˆ¹æœŸé—´éš”çš„å¹³å‡å€¼å’Œæ ‡å‡†å·®
    avg_interval = intervals.mean()
    std_interval = intervals.std(ddof=1) if len(intervals) > 1 else 0
    
    # ç­‰å¾…èˆ¹æœŸçš„å¹³å‡æ—¶é—´ï¼ˆå‡è®¾å‡åŒ€åˆ†å¸ƒï¼‰
    mu_w = avg_interval / 2
    # ç­‰å¾…æ—¶é—´çš„æ ‡å‡†å·®ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
    sigma_w = avg_interval / np.sqrt(12)
    
    # å‡è®¾å›ºå®šè¿è¾“æ—¶é—´30å¤©
    fixed_transit = 30
    
    # æ€»è¿è¾“å‘¨æœŸ = å›ºå®šè¿è¾“ + å¹³å‡ç­‰å¾…
    mu_l = fixed_transit + mu_w
    # è¿è¾“å‘¨æœŸæ³¢åŠ¨ä¸»è¦æ¥è‡ªç­‰å¾…æ—¶é—´æ³¢åŠ¨
    sigma_l = sigma_w
    
    return mu_l, sigma_l

def derive_leadtime_from_history(lead_df):
    """ä»å†å²è®°å½•è®¡ç®—è¿è¾“å‘¨æœŸ"""
    if "lead_time_days" in lead_df.columns:
        lt = pd.to_numeric(lead_df["lead_time_days"], errors="coerce").dropna()
    else:
        lt = (pd.to_datetime(lead_df["arrival_date"]) - 
              pd.to_datetime(lead_df["order_date"])).dt.days
        lt = lt.dropna()
    
    if len(lt) == 0:
        return 30, 5
    
    mu_l = lt.mean()
    sigma_l = lt.std(ddof=1) if len(lt) > 1 else 0
    
    return mu_l, sigma_l

def safety_stock(mu_d, sigma_d, mu_l, sigma_l, service):
    """è®¡ç®—å®‰å…¨åº“å­˜å’Œå†è®¢è´§ç‚¹"""
    if mu_d <= 0:
        return 0, 0
    
    # æœåŠ¡æ°´å¹³å¯¹åº”çš„zå€¼
    z = norm.ppf(service)
    
    # æ–¹å·®å…¬å¼ï¼šVar = L*Ïƒ_dÂ² + Î¼_dÂ²*Ïƒ_LÂ²
    var = mu_l * (sigma_d ** 2) + (mu_d ** 2) * (sigma_l ** 2)
    
    # å®‰å…¨åº“å­˜
    ss = z * np.sqrt(var) if var > 0 else 0
    
    # å†è®¢è´§ç‚¹ = å¹³å‡éœ€æ±‚ + å®‰å…¨åº“å­˜
    rop = mu_d * mu_l + ss
    
    return ss, rop

# ---------------------------
# ä¸»è®¡ç®—æµç¨‹
# ---------------------------
if ship_file and sales_file and ship_df is not None and sales_df is not None:
    
    st.divider()
    
    # è®¡ç®—è¿è¾“å‘¨æœŸå‚æ•°
    if use_custom_leadtime:
        mu_l = custom_mu_l
        sigma_l = custom_sigma_l
        st.info(f"ğŸ“Œ ä½¿ç”¨è‡ªå®šä¹‰è¿è¾“å‘¨æœŸï¼šå¹³å‡ {mu_l:.2f} å¤©ï¼Œæ³¢åŠ¨ {sigma_l:.2f} å¤©")
    elif lead_df is not None:
        mu_l, sigma_l = derive_leadtime_from_history(lead_df)
        st.success(f"âœ… ä½¿ç”¨è¿è¾“å‘¨æœŸå†å²è®°å½•ï¼šå¹³å‡ {mu_l:.2f} å¤©ï¼Œæ³¢åŠ¨ {sigma_l:.2f} å¤©")
    else:
        mu_l, sigma_l = derive_leadtime_from_schedule(ship_df)
        st.info(f"ğŸ“Š æ ¹æ®èˆ¹æœŸæ¨ç®—ï¼šå¹³å‡è¿è¾“å‘¨æœŸ {mu_l:.2f} å¤©ï¼Œæ³¢åŠ¨ {sigma_l:.2f} å¤©")
    
    # SKU åˆ—è¡¨
    sku_list = sorted(sales_df["sku"].unique())
    
    # æ·»åŠ è¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    result_list = []
    
    for idx, sku in enumerate(sku_list):
        status_text.text(f"æ­£åœ¨è®¡ç®— {sku}... ({idx+1}/{len(sku_list)})")
        progress_bar.progress((idx + 1) / len(sku_list))
        
        mu_d, sigma_d, cv = compute_demand_stats(sales_df, sku)
        ss, rop = safety_stock(mu_d, sigma_d, mu_l, sigma_l, service)
        
        # è®¡ç®—å‘¨è½¬å¤©æ•°
        turnover_days = (ss / mu_d) if mu_d > 0 else 0
        
        result_list.append({
            "SKU": sku,
            "å¹³å‡æ—¥é”€é‡": round(mu_d, 2),
            "æ—¥é”€é‡æ ‡å‡†å·®": round(sigma_d, 2),
            "éœ€æ±‚å˜å¼‚ç³»æ•°CV%": round(cv, 2),
            "å¹³å‡è¿è¾“å‘¨æœŸ(å¤©)": round(mu_l, 2),
            "è¿è¾“å‘¨æœŸæ ‡å‡†å·®(å¤©)": round(sigma_l, 2),
            "å®‰å…¨åº“å­˜": round(ss, 2),
            "å†è®¢è´§ç‚¹": round(rop, 2),
            "å®‰å…¨åº“å­˜å‘¨è½¬å¤©æ•°": round(turnover_days, 1),
            "æœåŠ¡æ°´å¹³": f"{service:.2%}"
        })
    
    progress_bar.empty()
    status_text.empty()
    
    result_df = pd.DataFrame(result_list)
    
    # ---------------------------
    # ç»“æœå±•ç¤º
    # ---------------------------
    st.header("ğŸ“Š è®¡ç®—ç»“æœ")
    
    # å…³é”®æŒ‡æ ‡å¡ç‰‡
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("SKUæ€»æ•°", len(result_df))
    with col2:
        st.metric("æ€»å®‰å…¨åº“å­˜", f"{result_df['å®‰å…¨åº“å­˜'].sum():,.0f}")
    with col3:
        st.metric("å¹³å‡æœåŠ¡æ°´å¹³", f"{service:.1%}")
    with col4:
        avg_turnover = result_df['å®‰å…¨åº“å­˜å‘¨è½¬å¤©æ•°'].mean()
        st.metric("å¹³å‡å‘¨è½¬å¤©æ•°", f"{avg_turnover:.1f}")
    
    st.divider()
    
    # ç»“æœè¡¨æ ¼ï¼ˆå¯æ’åºã€å¯ç­›é€‰ï¼‰
    st.subheader("ğŸ“‹ è¯¦ç»†è®¡ç®—ç»“æœ")
    
    # ç­›é€‰å™¨
    col1, col2 = st.columns([1, 3])
    with col1:
        filter_option = st.selectbox(
            "ç­›é€‰æ¡ä»¶",
            ["æ˜¾ç¤ºå…¨éƒ¨", "é«˜éœ€æ±‚æ³¢åŠ¨(CV>50%)", "ä½éœ€æ±‚æ³¢åŠ¨(CV<30%)", "é«˜å®‰å…¨åº“å­˜(>1000)"]
        )
    
    # åº”ç”¨ç­›é€‰
    filtered_df = result_df.copy()
    if filter_option == "é«˜éœ€æ±‚æ³¢åŠ¨(CV>50%)":
        filtered_df = filtered_df[filtered_df["éœ€æ±‚å˜å¼‚ç³»æ•°CV%"] > 50]
    elif filter_option == "ä½éœ€æ±‚æ³¢åŠ¨(CV<30%)":
        filtered_df = filtered_df[filtered_df["éœ€æ±‚å˜å¼‚ç³»æ•°CV%"] < 30]
    elif filter_option == "é«˜å®‰å…¨åº“å­˜(>1000)":
        filtered_df = filtered_df[filtered_df["å®‰å…¨åº“å­˜"] > 1000]
    
    st.dataframe(
        filtered_df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "SKU": st.column_config.TextColumn("SKU", width="small"),
            "å¹³å‡æ—¥é”€é‡": st.column_config.NumberColumn("å¹³å‡æ—¥é”€é‡", format="%.2f"),
            "éœ€æ±‚å˜å¼‚ç³»æ•°CV%": st.column_config.NumberColumn("éœ€æ±‚CV%", format="%.2f%%"),
            "å®‰å…¨åº“å­˜": st.column_config.NumberColumn("å®‰å…¨åº“å­˜", format="%.0f"),
            "å†è®¢è´§ç‚¹": st.column_config.NumberColumn("å†è®¢è´§ç‚¹", format="%.0f"),
        }
    )
    
    # ä¸‹è½½æŒ‰é’®
    output = BytesIO()
    result_df.to_excel(output, index=False, engine='openpyxl')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½Excelç»“æœ",
        data=output.getvalue(),
        file_name=f"safety_stock_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    # ---------------------------
    # å¯è§†åŒ–åˆ†æ
    # ---------------------------
    st.divider()
    st.header("ğŸ“ˆ æ•°æ®å¯è§†åŒ–åˆ†æ")
    
    tab1, tab2, tab3, tab4 = st.tabs(["é”€å”®è¶‹åŠ¿", "å®‰å…¨åº“å­˜åˆ†å¸ƒ", "éœ€æ±‚æ³¢åŠ¨åˆ†æ", "èˆ¹æœŸåˆ†æ"])
    
    with tab1:
        st.subheader("SKUé”€å”®è¶‹åŠ¿")
        sku_selected = st.selectbox("é€‰æ‹©SKU", sku_list, key="trend_sku")
        
        df_sku = sales_df[sales_df["sku"] == sku_selected].copy()
        daily_sales = df_sku.groupby("date")["quantity"].sum().reset_index()
        
        fig = px.line(
            daily_sales, 
            x="date", 
            y="quantity",
            title=f"{sku_selected} æ—¥é”€é‡è¶‹åŠ¿",
            labels={"date": "æ—¥æœŸ", "quantity": "é”€é‡"}
        )
        
        # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
        daily_sales['MA7'] = daily_sales['quantity'].rolling(window=7, min_periods=1).mean()
        fig.add_scatter(
            x=daily_sales['date'], 
            y=daily_sales['MA7'], 
            mode='lines',
            name='7æ—¥ç§»åŠ¨å¹³å‡',
            line=dict(dash='dash')
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        st.subheader("å®‰å…¨åº“å­˜åˆ†å¸ƒ")
        
        fig = px.bar(
            result_df.sort_values("å®‰å…¨åº“å­˜", ascending=False).head(20),
            x="SKU",
            y="å®‰å…¨åº“å­˜",
            title="TOP 20 å®‰å…¨åº“å­˜éœ€æ±‚SKU",
            labels={"å®‰å…¨åº“å­˜": "å®‰å…¨åº“å­˜æ•°é‡", "SKU": "SKUç¼–å·"},
            color="å®‰å…¨åº“å­˜",
            color_continuous_scale="Blues"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        st.subheader("éœ€æ±‚æ³¢åŠ¨æ€§åˆ†æ")
        
        fig = px.scatter(
            result_df,
            x="å¹³å‡æ—¥é”€é‡",
            y="éœ€æ±‚å˜å¼‚ç³»æ•°CV%",
            size="å®‰å…¨åº“å­˜",
            color="å®‰å…¨åº“å­˜å‘¨è½¬å¤©æ•°",
            hover_data=["SKU"],
            title="éœ€æ±‚ç‰¹å¾æ•£ç‚¹å›¾ï¼ˆæ°”æ³¡å¤§å°=å®‰å…¨åº“å­˜ï¼‰",
            labels={
                "å¹³å‡æ—¥é”€é‡": "å¹³å‡æ—¥é”€é‡",
                "éœ€æ±‚å˜å¼‚ç³»æ•°CV%": "éœ€æ±‚å˜å¼‚ç³»æ•° CV%",
                "å®‰å…¨åº“å­˜å‘¨è½¬å¤©æ•°": "å‘¨è½¬å¤©æ•°"
            },
            color_continuous_scale="Viridis"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.subheader("èˆ¹æœŸæ—¶é—´é—´éš”åˆ†æ")
        
        dates = ship_df["date"].sort_values().reset_index(drop=True)
        intervals = dates.diff().dt.days.dropna()
        
        if len(intervals) > 0:
            fig = go.Figure()
            fig.add_trace(go.Histogram(
                x=intervals,
                nbinsx=20,
                name="èˆ¹æœŸé—´éš”åˆ†å¸ƒ",
                marker_color='lightblue'
            ))
            fig.update_layout(
                title="èˆ¹æœŸæ—¶é—´é—´éš”åˆ†å¸ƒï¼ˆå¤©ï¼‰",
                xaxis_title="å¤©æ•°",
                yaxis_title="é¢‘æ¬¡",
                showlegend=True
            )
            st.plotly_chart(fig, use_container_width=True)
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å¹³å‡é—´éš”", f"{intervals.mean():.1f} å¤©")
            with col2:
                st.metric("æœ€å°é—´éš”", f"{intervals.min():.0f} å¤©")
            with col3:
                st.metric("æœ€å¤§é—´éš”", f"{intervals.max():.0f} å¤©")

else:
    st.warning("âš ï¸ è¯·è‡³å°‘ä¸Šä¼ **èˆ¹æœŸè¡¨**ä¸**é”€å”®è®°å½•**åå†è¿è¡Œè®¡ç®—")
    
    # ---------------------------
    # ç¤ºä¾‹æ•°æ®ä¸‹è½½
    # ---------------------------
    with st.expander("ğŸ“˜ æŸ¥çœ‹æ•°æ®æ ¼å¼è¯´æ˜å’Œç¤ºä¾‹"):
        st.markdown("""
        ### æ•°æ®æ ¼å¼è¦æ±‚
        
        #### 1. èˆ¹æœŸè¡¨ (ship_schedule.csv/xlsx)
        | åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
        |------|------|------|------|
        | date | æ—¥æœŸ | èˆ¹æœŸå‡ºå‘æ—¥æœŸ | 2025-08-01 |
        | voyage_id | æ–‡æœ¬(å¯é€‰) | èˆªæ¬¡ç¼–å· | V001 |
        | route | æ–‡æœ¬(å¯é€‰) | èˆªçº¿ | R1 |
        
        #### 2. é”€å”®è®°å½• (sales_history.csv/xlsx)
        | åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
        |------|------|------|------|
        | date | æ—¥æœŸ | é”€å”®æ—¥æœŸ | 2025-09-01 |
        | sku | æ–‡æœ¬ | äº§å“SKUç¼–å· | SKU-001 |
        | quantity | æ•°å€¼ | é”€å”®æ•°é‡ | 120 |
        
        #### 3. è¿è¾“å‘¨æœŸè®°å½• (leadtime_history.csv/xlsx, å¯é€‰)
        
        **æ–¹å¼Aï¼šåŒ…å«è¿è¾“å¤©æ•°åˆ—**
        | åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
        |------|------|------|------|
        | sku | æ–‡æœ¬(å¯é€‰) | äº§å“SKU | SKU-001 |
        | lead_time_days | æ•°å€¼ | è¿è¾“å¤©æ•° | 37 |
        
        **æ–¹å¼Bï¼šåŒ…å«è®¢å•å’Œåˆ°è´§æ—¥æœŸ**
        | åˆ—å | ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
        |------|------|------|------|
        | order_date | æ—¥æœŸ | è®¢å•æ—¥æœŸ | 2025-07-01 |
        | arrival_date | æ—¥æœŸ | åˆ°è´§æ—¥æœŸ | 2025-08-07 |
        | sku | æ–‡æœ¬(å¯é€‰) | äº§å“SKU | SKU-001 |
        
        ### è®¡ç®—æ–¹æ³•è¯´æ˜
        
        **å®‰å…¨åº“å­˜å…¬å¼ï¼š**
        ```
        SS = Z Ã— âˆš(L Ã— Ïƒ_dÂ² + Î¼_dÂ² Ã— Ïƒ_LÂ²)
        ```
        å…¶ä¸­ï¼š
        - Z: æœåŠ¡æ°´å¹³å¯¹åº”çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒåˆ†ä½æ•°
        - L: å¹³å‡è¿è¾“å‘¨æœŸ
        - Ïƒ_d: æ—¥éœ€æ±‚æ ‡å‡†å·®
        - Î¼_d: å¹³å‡æ—¥éœ€æ±‚
        - Ïƒ_L: è¿è¾“å‘¨æœŸæ ‡å‡†å·®
        
        **å†è®¢è´§ç‚¹ï¼š**
        ```
        ROP = Î¼_d Ã— L + SS
        ```
        """)
        
        # ç”Ÿæˆç¤ºä¾‹æ•°æ®
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # ç¤ºä¾‹èˆ¹æœŸæ•°æ®
            sample_ship = pd.DataFrame({
                'date': pd.date_range('2025-08-01', periods=12, freq='15D'),
                'voyage_id': [f'V{str(i).zfill(3)}' for i in range(1, 13)],
                'route': ['R1'] * 12
            })
            output_ship = BytesIO()
            sample_ship.to_csv(output_ship, index=False)
            st.download_button(
                "ğŸ“¥ ä¸‹è½½èˆ¹æœŸç¤ºä¾‹",
                data=output_ship.getvalue(),
                file_name="sample_ship_schedule.csv",
                mime="text/csv"
            )
        
        with col2:
            # ç¤ºä¾‹é”€å”®æ•°æ®
            dates = pd.date_range('2025-09-01', '2025-10-31', freq='D')
            sample_sales = pd.DataFrame({
                'date': np.tile(dates, 3),
                'sku': np.repeat(['SKU-001', 'SKU-002', 'SKU-003'], len(dates)),
                'quantity': np.random.poisson(100, len(dates) * 3)
            })
            output_sales = BytesIO()
            sample_sales.to_csv(output_sales, index=False)
            st.download_button(
                "ğŸ“¥ ä¸‹è½½é”€å”®ç¤ºä¾‹",
                data=output_sales.getvalue(),
                file_name="sample_sales_history.csv",
                mime="text/csv"
            )
        
        with col3:
            # ç¤ºä¾‹è¿è¾“å‘¨æœŸæ•°æ®
            sample_leadtime = pd.DataFrame({
                'order_date': pd.date_range('2025-07-01', periods=10, freq='7D'),
                'arrival_date': pd.date_range('2025-08-07', periods=10, freq='7D'),
                'sku': [f'SKU-{str(i % 3 + 1).zfill(3)}' for i in range(10)],
                'lead_time_days': np.random.normal(37, 5, 10).astype(int)
            })
            output_lead = BytesIO()
            sample_leadtime.to_csv(output_lead, index=False)
            st.download_button(
                "ğŸ“¥ ä¸‹è½½è¿è¾“å‘¨æœŸç¤ºä¾‹",
                data=output_lead.getvalue(),
                file_name="sample_leadtime_history.csv",
                mime="text/csv"
            )
